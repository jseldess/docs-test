"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2608],{7017:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>l,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var n=r(5893),t=r(1151);const a={title:"Understanding hybrid search",category:"6495c32609a24b00434e5b53"},o=void 0,i={id:"data/hybrid-search-and-sparse-vectors/hybrid-search",title:"Understanding hybrid search",description:"Overview",source:"@site/versioned_docs/version-legacy/data/hybrid-search-and-sparse-vectors/hybrid-search.md",sourceDirName:"data/hybrid-search-and-sparse-vectors",slug:"/data/hybrid-search-and-sparse-vectors/hybrid-search",permalink:"/docs/legacy/data/hybrid-search-and-sparse-vectors/hybrid-search",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/versioned_docs/version-legacy/data/hybrid-search-and-sparse-vectors/hybrid-search.md",tags:[],version:"legacy",frontMatter:{title:"Understanding hybrid search",category:"6495c32609a24b00434e5b53"},sidebar:"examplesSidebar",previous:{title:"Encoding sparse vectors",permalink:"/docs/legacy/data/hybrid-search-and-sparse-vectors/encode-sparse-vectors"},next:{title:"Querying sparse-dense vectors",permalink:"/docs/legacy/data/hybrid-search-and-sparse-vectors/query-sparse-dense-vectors"}},c={},d=[{value:"Overview",id:"overview",level:2},{value:"Hybrid search in Pinecone",id:"hybrid-search-in-pinecone",level:2},{value:"Dense vectors",id:"dense-vectors",level:3},{value:"Sparse vectors",id:"sparse-vectors",level:3},{value:"Sparse-dense workflow",id:"sparse-dense-workflow",level:2},{value:"Creating sparse vector embeddings",id:"creating-sparse-vector-embeddings",level:2},{value:"Creating sparse-dense vectors",id:"creating-sparse-dense-vectors",level:2},{value:"Querying sparse-dense vectors",id:"querying-sparse-dense-vectors",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Next steps",id:"next-steps",level:2}];function h(e){const s={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(s.p,{children:["Pinecone supports vectors with sparse and dense values, which allows you to perform hybrid search on your Pinecone index. Hybrid search combines semantic and keyword search in one query for more relevant results. Semantic search results for out-of-domain queries can be less relevant; ",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2210.11934",children:"combining these with keyword search results can improve relevance"}),". This topic describes how hybrid search with sparse-dense vectors works in Pinecone."]}),"\n",(0,n.jsxs)(s.p,{children:["To see sparse-dense embeddings in action, see the ",(0,n.jsx)(s.a,{href:"https://github.com/pinecone-io/examples/blob/master/learn/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb",children:"Ecommerce hybrid search example"}),"."]}),"\n",(0,n.jsx)(s.h2,{id:"hybrid-search-in-pinecone",children:"Hybrid search in Pinecone"}),"\n",(0,n.jsxs)(s.p,{children:["In Pinecone, you perform hybrid search with ",(0,n.jsx)(s.strong,{children:"sparse-dense vectors"}),". Sparse-dense vectors combine ",(0,n.jsx)(s.a,{href:"https://www.pinecone.io/learn/dense-vector-embeddings-nlp/#dense-vs-sparse-vectors",children:"dense and sparse embeddings"})," as a single vector. Sparse and dense vectors represent different types of information and enable distinct kinds of search."]}),"\n",(0,n.jsx)(s.h3,{id:"dense-vectors",children:"Dense vectors"}),"\n",(0,n.jsxs)(s.p,{children:["The basic vector type in Pinecone is a ",(0,n.jsx)(s.a,{href:"https://www.pinecone.io/learn/dense-vector-embeddings-nlp/",children:"dense vector"}),". Dense vectors enable semantic search. Semantic search returns the most similar results according to a specific distance metric even if no exact matches are present. This is possible because dense vectors generated by embedding models such as ",(0,n.jsx)(s.a,{href:"https://huggingface.co/sentence-transformers",children:"SBERT"})," are numerical representations of semantic meaning."]}),"\n",(0,n.jsx)(s.h3,{id:"sparse-vectors",children:"Sparse vectors"}),"\n",(0,n.jsxs)(s.p,{children:["Sparse vectors have very large number of dimensions, where only a small proportion of values are non-zero. When used for keywords search, each sparse vector represents a document; the dimensions represent words from a dictionary, and the values represent the importance of these words in the document. Keyword search algorithms like the ",(0,n.jsx)(s.a,{href:"https://en.wikipedia.org/wiki/Okapi_BM25",children:"BM25"})," algorithm compute the relevance of text documents based on the number of keyword matches, their frequency, and other factors."]}),"\n",(0,n.jsx)(s.h2,{id:"sparse-dense-workflow",children:"Sparse-dense workflow"}),"\n",(0,n.jsx)(s.p,{children:"Using sparse-dense vectors involves the following general steps:"}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsx)(s.li,{children:"Create dense vectors using an external embedding model."}),"\n",(0,n.jsx)(s.li,{children:"Create sparse vectors using an external model."}),"\n",(0,n.jsxs)(s.li,{children:["Create an index that supports sparse-dense vectors (s1 or p1 with the ",(0,n.jsx)(s.code,{children:"dotproduct"})," metric)."]}),"\n",(0,n.jsx)(s.li,{children:"Upsert dense and sparse vectors to your index."}),"\n",(0,n.jsx)(s.li,{children:"Search the index using sparse-dense vectors."}),"\n",(0,n.jsx)(s.li,{children:"Pinecone returns sparse-dense vectors."}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"creating-sparse-vector-embeddings",children:"Creating sparse vector embeddings"}),"\n",(0,n.jsx)(s.p,{children:"Keyword-aware semantic search requires vector representations of documents. Because Pinecone indexes accept sparse indexes rather than documents, you can control the generation of sparse vectors to represent documents."}),"\n",(0,n.jsxs)(s.p,{children:["Because Pinecone allows you to create your own sparse vectors, you can use sparse-dense queries to solve the Maximum Inner Product Search (MIPS) problem for sparse-dense vectors of any real values. This includes emerging use-cases such as retrieval over learnt sparse representations for text data using ",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2107.05720",children:"SPLADE"}),"."]}),"\n",(0,n.jsxs)(s.p,{children:["For examples of sparse vector generation, see ",(0,n.jsx)(s.a,{href:"https://www.pinecone.io/learn/splade/",children:"SPLADE for Sparse Vector Search Explained"}),", our ",(0,n.jsx)(s.a,{href:"https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/search/semantic-search/sparse/splade/splade-vector-generation.ipynb",children:"SPLADE generation notebook"}),", and our ",(0,n.jsx)(s.a,{href:"https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/search/semantic-search/sparse/bm25/bm25-vector-generation.ipynb",children:"BM25 generation notebook"}),"."]}),"\n",(0,n.jsx)(s.h2,{id:"creating-sparse-dense-vectors",children:"Creating sparse-dense vectors"}),"\n",(0,n.jsxs)(s.p,{children:["In Pinecone, each vector consists of dense vector values and, optionally, sparse vector values as well. When you upsert records with sparse and dense vector values, Pinecone creates sparse-dense vectors from your sparse and dense embeddings. Pinecone does not support vectors with only sparse values. See ",(0,n.jsx)(s.a,{href:"upserting-sparse-dense-records",children:"Upserting sparse-dense records"}),"."]}),"\n",(0,n.jsx)(s.h2,{id:"querying-sparse-dense-vectors",children:"Querying sparse-dense vectors"}),"\n",(0,n.jsxs)(s.p,{children:["To query your sparse-dense vectors, you provide a query vector containing both sparse and dense values. Pinecone ranks vectors in your index by considering the full dot product over the entire vector; the score of a vector is the sum of the dot product of its dense values with the dense part of the query, together with the dot product of its sparse values with the sparse part of the query. You may want to ",(0,n.jsx)(s.a,{href:"weighting-sparse-and-dense-vectors",children:"weight the sparse or dense vector component more heavily"}),"."]}),"\n",(0,n.jsx)(s.h2,{id:"limitations",children:"Limitations"}),"\n",(0,n.jsx)(s.p,{children:"Pinecone sparse-dense vectors have the following limitations:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Pinecone supports sparse vector values of sizes up to 1000 non-zero values."}),"\n",(0,n.jsxs)(s.li,{children:["Pinecone only supports upserting sparse-dense vectors to ",(0,n.jsx)(s.code,{children:"p1"})," and ",(0,n.jsx)(s.code,{children:"s1"})," indexes."]}),"\n",(0,n.jsxs)(s.li,{children:["In order to query an index using sparse values, the index must use the ",(0,n.jsxs)(s.a,{href:"indexes#distance-metrics",children:[(0,n.jsx)(s.code,{children:"dotproduct"})," metric"]}),". Attempting to query any other index with sparse values returns an error."]}),"\n",(0,n.jsx)(s.li,{children:"Indexes created before February 22, 2023 do not support sparse values."}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:(0,n.jsx)(s.a,{href:"https://github.com/pinecone-io/examples/blob/master/learn/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb",children:"Ecommerce hybrid search example"})}),"\n"]}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:(0,n.jsx)(s.a,{href:"upserting-sparse-dense-records",children:"Upserting sparse-dense records"})}),"\n"]})]})}function l(e={}){const{wrapper:s}={...(0,t.a)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},1151:(e,s,r)=>{r.d(s,{Z:()=>i,a:()=>o});var n=r(7294);const t={},a=n.createContext(t);function o(e){const s=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function i(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),n.createElement(a.Provider,{value:s},e.children)}}}]);